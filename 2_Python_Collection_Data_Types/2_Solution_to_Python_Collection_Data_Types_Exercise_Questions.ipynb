{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e217ede8-c5ad-442d-bcae-0f4e380b1cc0",
   "metadata": {},
   "source": [
    "# Solutions to `Python Collection Data Types` Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761e2d2-7804-4a55-90c0-dfd0bf8a6618",
   "metadata": {},
   "source": [
    "## 1. The output of running this code\n",
    "\n",
    "The code will raise an `IndexError` because we are trying to access an index of `list_1` that does not exist (it is empty). When `item` is `0`, it tries to execute `list_1[0].append(0)`, but `list_1` has no elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77470557-d112-4c3d-8d62-95b9d8ad02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = []     # initialize an empty list\n",
    "for item in range(3):\n",
    "    list_1[item].append(item)  # this will raise an error because list_1 is empty\n",
    "print(item)    # print the last value of item in the loop\n",
    "print(list_1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415775e-3da1-4946-8509-974dd4db7c2e",
   "metadata": {},
   "source": [
    "## 2. Accessing Index 10 in a `list` or `tuple`\n",
    "\n",
    "Attempting to access index `10` in the list `numbers` will raise an `IndexError` because valid indices are `0` to `9` for a list of size `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffb30d-730c-4558-b275-f2abe80daed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "print(numbers[10])  # this will raise an IndexError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a426f0-684f-482a-acb3-59cffeab20b2",
   "metadata": {},
   "source": [
    "## 3. `tuple` Conversion\n",
    "\n",
    "After converting the tuple to a list and adding two items, converting it back results in `final_tuple` containing `(1, 2, 3, 4, 5, 6, 7)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf3940-6dff-437b-a747-f823741e16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tuple = (1, 2, 3, 4, 5)\n",
    "\n",
    "temp_list = list(original_tuple)  # tuple to list\n",
    "\n",
    "temp_list.append(6)  # add an item to the end of the list\n",
    "temp_list.append(7)  # add an item to the end of the list \n",
    "\n",
    "final_tuple = tuple(temp_list)   # list to tuple\n",
    "print(final_tuple) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be63cd-727e-4c1a-a9a4-0fbd98feaece",
   "metadata": {},
   "source": [
    "## 4. Modifying a `tuple`\n",
    "\n",
    "Attempting to directly change an element of a `tuple` will raise a `TypeError`. The proper method is to convert it to a `list`, modify the `list`, and then convert it back to a `tuple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3e003-3b2e-4418-8bb1-7fb941845977",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tuple = (10, 20, 30, 40, 50)\n",
    "\n",
    "# my_tuple[2] = 35  # this will raise a TypeError because tuples are immutable\n",
    "\n",
    "# modify tuple contents\n",
    "temp_list = list(my_tuple)         # convert to a list\n",
    "temp_list[2] = 35                  # modify it\n",
    "modified_tuple = tuple(temp_list)  # modify back to a tuple\n",
    "print(modified_tuple)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b91ef6-ac80-4042-9090-48c341888759",
   "metadata": {},
   "source": [
    "## 5. Reversing a String and Slicing\n",
    "\n",
    "The reversed string is `\"!nuf si nohtyP\"`, and extracting characters from index `3` to `8` gives `\"nuf si\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb25344a-895e-42e6-8e64-e7027af45f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f si \n"
     ]
    }
   ],
   "source": [
    "str_a = \"Python is fun!\"\n",
    "\n",
    "# Thanks Tina (Yina) Zhou (BARM 2025), for fixing the mistake in the indices\n",
    "reversed_str = str_a[::-1]       # reverse it using slicing\n",
    "sliced_str = reversed_str[3:8]   # extract from the 4th to the 8th position (inclusive)\n",
    "print(sliced_str)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd0050-f08a-4cca-8677-6bb80f73ddd7",
   "metadata": {},
   "source": [
    "## 6. `range` and `list` Modification\n",
    "\n",
    "Modifying an item in the converted `list` works, but trying to modify an item directly in the `range` will raise a `TypeError` since ranges are immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29502b-5a13-44dd-bfaa-41b743831b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_range = range(5, 26, 3)  # output 5, 8, 11, 14, 17, 20, 23\n",
    "\n",
    "num_list = list(num_range)   # range to a list\n",
    "\n",
    "num_list[4] = 100            # changing the 4th item\n",
    "print(num_list)  \n",
    "\n",
    "# try changing directly in the range\n",
    "num_range[4] = 100  # this raises a TypeError because ranges are immutable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2388e-a06d-42e4-b324-64e8b678298c",
   "metadata": {},
   "source": [
    "## 7. Generating a Sequence and Summing\n",
    "\n",
    "The sequence generated will be `[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]`, and the sum of these elements will be `550`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12eade-4f17-4725-baef-26badbc52eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = range(0, 101, 10)\n",
    "seq_list = list(seq_range)  # convert range into a list\n",
    "\n",
    "total_sum = sum(seq_list)   # sum it up\n",
    "print(total_sum)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca6454-7a55-4531-9784-afc586829367",
   "metadata": {},
   "source": [
    "## 8. Cumulative Sum of Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc32aa3-0d74-4a59-b725-09160b5feac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = [100, 150, 200, 250, 300, 350, 400]  # weekly sales\n",
    "\n",
    "cumsum_sales = []        # initialize an empty list for cumulative sums\n",
    "current_sum = 0          # initialize current sum\n",
    "\n",
    "for sale in sales:       # loop through each sale\n",
    "    current_sum += sale  # add current sale to current sum\n",
    "    cumsum_sales.append(current_sum)  # append the cumulative sum to the list\n",
    "\n",
    "print(cumsum_sales)  # output: [100, 250, 450, 700, 1000, 1350, 1750]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6b109-5dca-4d1a-b9a1-abbb2e1139d6",
   "metadata": {},
   "source": [
    "## 8.1. Additional challenge: Running Average Calculation\n",
    "\n",
    "The running average is calculated by dividing the cumulative total by the number of days (using the index) and storing it in `running_avg_sales`. Remember that the index starts from `0`; hence, we need the `index + 1` to account for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983206e-c2d3-498c-a8f6-4d7ab568d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_avg_sales = []    # initialize an empty list for running averages\n",
    "total_sum = 0             # initialize total sum\n",
    "\n",
    "for index, sale in enumerate(sales):  # loop through each sale with index\n",
    "    total_sum += sale                 # add current sale to total sum\n",
    "    running_average = total_sum / (index + 1)  # calculate running average\n",
    "    running_avg_sales.append(running_average)  # append to the list\n",
    "\n",
    "print(running_avg_sales)  # output: [100.0, 125.0, 150.0, 175.0, 200.0, 225.0, 250.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e52548-402b-4364-86cb-a9e22391ff80",
   "metadata": {},
   "source": [
    "## 9. Swapping Keys and Values in a Dictionary\n",
    "\n",
    "The code creates a new dictionary `swapped_dict` by swapping the keys and values from `alphabet_dict` using dictionary comprehension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae3aaf-8c73-4f99-ae70-68625f3a3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\n",
    "\n",
    "swapped_dict = {value: key for key, value in alphabet_dict.items()}  # swap key, value\n",
    "print(swapped_dict)  # output: {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5baf9-38f3-4ac0-8740-dcb3df2d1b80",
   "metadata": {},
   "source": [
    "## 10. Average Sales Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da8b89-beb0-44b1-ba80-9abde187322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sales = [200, 300, 250, 400, 350, 380, 420]\n",
    "\n",
    "average_sales = sum(weekly_sales) / len(weekly_sales) \n",
    "print(f'Average sales: {average_sales:.4f}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ba870-1c93-44bc-ad26-13d8b3ae8205",
   "metadata": {},
   "source": [
    "## 11. Calculate the Sample Standard Deviation of Stock Prices\n",
    "\n",
    "The sample standard deviation is calculated using the formula provided. First, we compute the mean of the stock prices. Then, we calculate the variance using list comprehension to find the squared differences from the mean, summing them up, and dividing by `n-1` (degrees of freedom). Finally, we take the square root of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464a997-72b7-4408-97b0-9674c2aee43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "stock_prices = [100, 102, 98, 105, 107, 106, 103, 110, 108, 107]\n",
    "mean_price = sum(stock_prices) / len(stock_prices)\n",
    "\n",
    "variance = sum([(price - mean_price) ** 2 for price in stock_prices]) / (len(stock_prices) - 1)\n",
    "std_deviation = math.sqrt(variance)  \n",
    "\n",
    "print(f'Sample Standard Deviation of Stock Prices: {std_deviation:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf18a9-c87a-4aa7-b37e-761dd0ecd9a9",
   "metadata": {},
   "source": [
    "## 12. Set Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e6443-eba1-4614-9b0c-59861fbe73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sets\n",
    "set_a = {1, 2, 3, 4, 5}\n",
    "set_b = {4, 5, 6, 7, 8}\n",
    "\n",
    "union_result = set_a.union(set_b)                # union\n",
    "intersection_result = set_a.intersection(set_b)  # intersection\n",
    "difference_result = set_a.difference(set_b)      # difference\n",
    "is_subset = set_a.issubset(set_b)                # check subset relationship\n",
    "\n",
    "print(f'Union: {union_result}')  \n",
    "print(f'Intersection: {intersection_result}') \n",
    "print(f'Difference (set_a - set_b): {difference_result}')\n",
    "print(f'Is set_a a subset of set_b? {is_subset}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97759c-77b9-46fd-b931-0dff8fa7c69d",
   "metadata": {},
   "source": [
    "## 13. Creating a Frozenset\n",
    "\n",
    "A `frozenset` is an immutable version of a `set`. When attempting to add a new number, an `AttributeError` occurs because `frozensets` do not support modification after creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82835c-ee86-45c5-a698-5cbe0989042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [10, 20, 30, 40, 50]\n",
    "frozen_numbers = frozenset(numbers)  # list to frozenset\n",
    "\n",
    "frozen_numbers.add(60)               # This will raise an AttributeError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a72a9-0235-4466-8ac4-3e54956e7d1e",
   "metadata": {},
   "source": [
    "## 14. Comparing Stock Prices of Two Companies\n",
    "\n",
    "This snippet uses list comprehension to find the indices (days) where the stock price of company B is higher than that of company A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac8abb-123f-425e-a2e5-1786c9dd766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_A = [100, 102, 98, 105, 107, 106, 103, 110, 108, 107]\n",
    "prices_B = [101, 103, 99, 106, 108, 105, 102, 111, 109, 108]\n",
    "\n",
    "higher_prices_days = [day for day in range(len(prices_A)) if prices_B[day] > prices_A[day]]\n",
    "\n",
    "print(f'Days when company B had a higher closing price than company A: {higher_prices_days}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c25c4c-55cb-41f1-b4f7-27bd4d562ed2",
   "metadata": {},
   "source": [
    "## 15. Squaring Odd Numbers\n",
    "\n",
    "The list comprehension filters the odd numbers from `numbers`, squaring each odd number and storing it in the new list `squared_odds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4be164-7b24-40bf-b87f-e94d882a5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = list(range(1, 51))  # list of numbers 1, 2, ..., 50\n",
    "\n",
    "squared_odds = [num ** 2 for num in numbers if num % 2 != 0]\n",
    "\n",
    "print(f'Squares of odd numbers: {squared_odds}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7cd1e0-6c97-4584-9a23-014ff54b2e0e",
   "metadata": {},
   "source": [
    "## 16. Difference Between Two Snippets Deleting List Elements\n",
    "\n",
    "Snippet A clears the original list in place, preserving its identity (the same object in memory). Snippet B creates a new list and reassigns `sample_list_b`, resulting in a different object (a new id)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d92c685-f477-49c9-85be-a860cd143b90",
   "metadata": {},
   "source": [
    "### Snippet A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efde76-0f48-47ce-b25b-ac1f63cae271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_a = [10, 20, 30]\n",
    "print(f'old id: {id(sample_list_a)}')\n",
    "sample_list_a[:] = []  # clear the list using slice assignment\n",
    "print(sample_list_a)  \n",
    "print(f'ID after Snippet A: {id(sample_list_a)}')  # show the id of the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f212f4-28ac-495b-b696-8cce9a691440",
   "metadata": {},
   "source": [
    "### Snippet B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434f067-350f-48c8-a7bf-4722b4dfe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_b = [10, 20, 30]\n",
    "print(f'old id: {id(sample_list_b)}')\n",
    "sample_list_b = []  # reassign to a new empty list\n",
    "print(sample_list_b)  \n",
    "print(f'ID after Snippet B: {id(sample_list_b)}')  # show the id of the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c592480-7c62-4e4f-a8e7-918a1df2b6d8",
   "metadata": {},
   "source": [
    "## 17. Student Scores Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37938ec8-2ec6-4ec9-89df-a40777746c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_scores = {\n",
    "    'Vicky': {\n",
    "        'Data Analytics': 85,\n",
    "        'Business Analytics': 90,\n",
    "        'Python for Data Analysis': 88\n",
    "    },\n",
    "    'Tina': {\n",
    "        'Data Analytics': 78,\n",
    "        'Business Analytics': 82,\n",
    "        'Python for Data Analysis': 85\n",
    "    },\n",
    "    'George': {\n",
    "        'Data Analytics': 92,\n",
    "        'Business Analytics': 95,\n",
    "        'Python for Data Analysis': 89\n",
    "    }\n",
    "}\n",
    "\n",
    "# access and print the Business Analytics score of the second student\n",
    "Tina_BA_score = students_scores['Tina']['Business Analytics']\n",
    "print(f\"Tina's Business Analytics score: {Tina_BA_score}\")  \n",
    "\n",
    "# update the Python for Data Analysis score of the first student\n",
    "students_scores['Vicky']['Python for Data Analysis'] = 90  # updating\n",
    "print(f\"Updated Python for Data Analysis score for Vicky: {students_scores[\"Vicky\"][\"Python for Data Analysis\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61245415-6bf1-4fc3-8f3f-90f82ca4f65e",
   "metadata": {},
   "source": [
    "## 18. Warehouse Demand Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0b586-c797-4b46-ad15-dd3216ae8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "probabilities = [0.1, 0.05, 0.07, 0.01, 0.08, 0.12, 0.15, 0.09, 0.14, 0.09]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a55adf-14d6-414f-ad57-fb4aec9331db",
   "metadata": {},
   "source": [
    "### 18a. combine demand and probabilities into a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a5291-3172-47db-8a93-638bace3d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_dict = dict(zip(demand, probabilities))  # combine using zip\n",
    "print(f'Demand dictionary: {demand_dict}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c8f746-823e-4cbb-a35d-77063a818d3b",
   "metadata": {},
   "source": [
    "### 18b. Calculate expected daily demand and variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098477c-eb8f-4f1e-a34d-9afd35bf5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_demand = sum([d * p for d, p in demand_dict.items()])  # E(X)\n",
    "expected_demand_squared = sum([d**2 * p for d, p in demand_dict.items()])  # E(X^2)\n",
    "variance = expected_demand_squared - (expected_demand ** 2)  # E(X^2) - E(X)^2\n",
    "\n",
    "print(f'Expected Daily Demand: {expected_demand}')\n",
    "print(f'Variance of Daily Demand: {variance}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c04ff-7ee7-484c-90cb-06ac8f9f5648",
   "metadata": {},
   "source": [
    "### 18c. calculate daily cost Y = 100X\n",
    "The code combines demand and probabilities into a dictionary using `zip()`, calculates the expected demand and variance using dictionary comprehension, and computes the mean and variance of the daily cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7550c8-8331-4a2f-b3a4-d8e4a37a3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per_use = 100  \n",
    "mean_cost =  cost_per_use * expected_demand   # E(Y) = 100* E(X)\n",
    "variance_cost = (cost_per_use ** 2) * variance   # V(Y) = 100^2 * V(X)\n",
    "\n",
    "print(f'Mean Daily Cost: {mean_cost}')  \n",
    "print(f'Variance of Daily Cost: {variance_cost}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f547e38-0e25-4a53-8f1a-e6730765ca0f",
   "metadata": {},
   "source": [
    "## 19. Dictionary Key Case Sensitivity\n",
    "\n",
    "In Python, dictionary keys are case-sensitive, so `'Anna'` and `'anna'` are treated as distinct keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5527200-9aa3-47e5-acb8-af15d64ca508",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_dict = {'Anna': 25, 'Jason': 30, 'Nadia': 35}\n",
    "\n",
    "ages_dict['anna'] = 28  # adding with different case\n",
    "\n",
    "print(ages_dict)  # output without error shows that 'Anna' and 'anna' are treated as different keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82075b-61fd-47f1-8c30-f9469bb70323",
   "metadata": {},
   "source": [
    "## 20. Counting Characters in a String\n",
    "\n",
    "This snippet counts each character in `str_1`, ignoring spaces and ensuring the count is case-insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfc09e-f42e-4b54-847e-625e8728db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_1 = \"Success is the result of consistent, persistent effort.\"\n",
    "\n",
    "char_count = {}  # initialize an empty dictionary\n",
    "\n",
    "for char in str_1:  # loop through each character in the string\n",
    "    if char != ' ':  # ignore spaces\n",
    "        char_lower = char.lower()    # convert to lower case for case insensitivity\n",
    "        if char_lower in char_count: # if we have seen this character before\n",
    "            char_count[char_lower] += 1  # increment the count if already in dictionary\n",
    "        else:\n",
    "            char_count[char_lower] = 1  # initialize count for this new character\n",
    "\n",
    "print(char_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28247420-d1b8-43b5-92aa-90b20bb73e9f",
   "metadata": {},
   "source": [
    "## 21. Unique Elements from a List\n",
    "\n",
    "This snippet shows two methods for extracting unique elements from a list: one using the `set()` function and the other using a manual check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a0b24-8d62-4257-b5ed-687cf9dfe634",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nums = [1, 2, 1, 3, 5, 7, 7, 6, 3, 10, 7, 2, 1]\n",
    "\n",
    "# Method 1: using set() to get unique elements\n",
    "unique_with_set = list(set(list_nums))  # convert to set and back to list\n",
    "print(f'Unique elements using set: {unique_with_set}')\n",
    "\n",
    "# Method 2: Without using set()\n",
    "unique_without_set = []  # initialize empty list for unique elements\n",
    "for num in list_nums:\n",
    "    if num not in unique_without_set:  # if the number is not already in the list\n",
    "        unique_without_set.append(num)  # add unique number to the list\n",
    "\n",
    "print(f'Unique elements without using set: {unique_without_set}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16216b9d-bcc5-43a6-9e37-723cb55dfcff",
   "metadata": {},
   "source": [
    "## 22. Employee Salary Adjustment\n",
    "This code iterates through the `employees` dictionary and increases the salary of those earning less than $50_000 by 10%, updating the dictionary in place. Do you think this can be done with a dictionary comprehension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e24faf-229c-487f-8517-a854e18dba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = {'Emily': 48_000, 'Andrew': 52_000, 'Mike': 47_000, 'Anna': 60_000}\n",
    "\n",
    "for employee, salary in employees.items():  # loop through each employee\n",
    "    if salary < 50_000:\n",
    "        employees[employee] *= 1.1  # increase salary by 10%\n",
    "\n",
    "print('Updated Salaries:', employees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c482a-3d9a-4cb1-9912-13edad46ab02",
   "metadata": {},
   "source": [
    "## 23. Salary Analysis\n",
    "\n",
    "The mean is calculated by summing the salaries and dividing by the number of salaries. The median is determined by sorting the list and finding the middle value(s). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c888b72-d066-426f-8395-51523810232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = [50, 40, 500, 50, 40, 50, 40, 40, 80, 40]\n",
    "n = len(salaries)\n",
    "mean_salary = sum(salaries) / n     # mean salary\n",
    "\n",
    "sorted_salaries = sorted(salaries)  # sort salaries for finding median\n",
    "\n",
    "# median salary\n",
    "if n % 2 == 1:  # if number of data points is odd\n",
    "    median_salary = sorted_salaries[n // 2]  # middle value\n",
    "else:  # if number of data points is even\n",
    "    # average of two middle values\n",
    "    median_salary = (sorted_salaries[n // 2 - 1] + sorted_salaries[n // 2 ]) / 2  \n",
    "    # remember in the above line that the indexes start from 0! \n",
    "\n",
    "print(f'Mean Salary: {mean_salary}')  \n",
    "print(f'Median Salary: {median_salary}')\n",
    "print(\"\"\"\\nThe significant difference between the mean and median exists due to \n",
    "the presence of an outlier (the $500 salary), which skews the mean upwards. \n",
    "Therefore, using the mean to represent employees' average salary could lead to \n",
    "misleading conclusions. In such cases, the median is a more appropriate measure, \n",
    "as it is less affected by outliers, ensuring more accurate reporting.\\n\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4ba6c-3921-4ba7-8adb-49929d1e8225",
   "metadata": {},
   "source": [
    "## 23 (Alternative) \n",
    "As an alternative, libraries with statistical calculation capabilities such as statistics, numpy, or pandas can be used to calculate the mean and median. Below is a solution for finding the mean and median using the statistics module from Python's standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f19e2-d05c-4d17-946a-147ce41a413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "salaries = [50, 40, 500, 50, 40, 50, 40, 40, 80, 40]\n",
    "\n",
    "mean_stat = statistics.mean(salaries)  # calculate the mean using statistics module\n",
    "median_stat = statistics.median(salaries)  # calculate the median using statistics module\n",
    "\n",
    "print(f'Mean using statistics module: {mean_stat}')\n",
    "print(f'Median using statistics module: {median_stat}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14a347-660a-43c8-ace3-fc7c39e0c2d1",
   "metadata": {},
   "source": [
    "## 24. Shoe Size Sales Analysis\n",
    "### 24a. Find mean, median, and mode of the sold shoe sizes\n",
    "\n",
    "The mean is calculated as before. The median is found by sorting the list. The mode is determined by counting the occurrences of each size in the list and identifying the most common sizes. `mode` is a more appropriate metric here as we are looking for ordering the most popular size (size that is sold the most)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a10230-e802-494c-8d51-8e20d225c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_sizes = [\n",
    "    10, 9, 7, 6, 11, 8, 7, 9, 10, 8, 7, 12, 6, 9, 10, 9, 10, 10, 8, 7,\n",
    "    7, 6, 8, 9, 7, 11, 6, 6, 9, 8, 7, 9, 8, 10, 11, 7, 7, 6, 12, 10,\n",
    "    8, 7, 10, 11, 9, 7, 8, 8, 7, 6, 12, 8, 10, 6, 10, 11, 9, 7, 6, 7,\n",
    "    8, 10, 9, 12, 11, 6, 10, 6, 9, 7, 9, 7, 8, 10, 7, 9, 7, 10, 8, 8,\n",
    "    7, 8, 9, 11, 12, 9, 10, 8, 11, 9, 6, 10, 7, 6, 7, 6, 10, 8, 9, 12\n",
    "]\n",
    "\n",
    "n = len(shoe_sizes)\n",
    "mean_shoe_size = sum(shoe_sizes) / n    # mean\n",
    "sorted_shoe_sizes = sorted(shoe_sizes)  # sort shoe sizes\n",
    "\n",
    "if n % 2 == 1:  \n",
    "    median_shoe_size = sorted_shoe_sizes[n // 2]  # middle value\n",
    "else:  \n",
    "    median_shoe_size = (sorted_shoe_sizes[n // 2 - 1] + sorted_shoe_sizes[n // 2]) / 2  # average of two middle values\n",
    "\n",
    "mode_count = {}  # dictionary to count occurrences to find mode\n",
    "for size in shoe_sizes:\n",
    "    mode_count[size] = mode_count.get(size, 0) + 1  # if first time encountering, get 1. \n",
    "                                                    # otherwise, add 1 to count \n",
    "\n",
    "# Find the mode(s)\n",
    "max_count = max(mode_count.values())  # highest frequency\n",
    "mode_sizes = [size for size, count in mode_count.items() if count == max_count]  # sizes with highest frequency\n",
    "\n",
    "print(f'Mean Shoe Size: {mean_shoe_size}')  \n",
    "print(f'Median Shoe Size: {median_shoe_size}')  \n",
    "print(f'Mode Shoe Sizes: {mode_sizes}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c6b92-35f1-4bd5-be6f-8e8068808146",
   "metadata": {},
   "source": [
    "## 25. Stock Price Analysis\n",
    "The code calculates the sample covariance between Nvidia and Microsoft stock prices using list comprehension, sample variance for Apple stock prices, and covariance of Apple stock prices with itself, which is equal to its variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b33d7-9fc8-4989-9ee0-fdb9d3bb3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia prices\n",
    "nvid_p = [113.37, 117.87, 116.0, 116.26, 120.87, 123.51, 124.04,\n",
    "          121.4, 121.44, 117.0, 118.85, 122.85, 124.92, 127.72, \n",
    "          132.89, 132.65, 134.81, 134.8, 138.07, 131.6, 135.72, 136.93]\n",
    "\n",
    "# apple prices\n",
    "appl_p = [220.69, 228.87, 228.2, 226.47, 227.37, 226.37, 227.52, 227.79,\n",
    "          233.0, 226.21, 226.78, 225.67, 226.8, 221.69, 225.77, 229.54, \n",
    "          229.04, 227.55, 231.3, 233.85, 231.78, 232.15]\n",
    "\n",
    "# microsoft prices\n",
    "msft_p = [430.81, 438.69, 435.27, 433.51, 429.17, 432.11, 431.31, \n",
    "                   428.02, 430.3, 420.69, 417.13, 416.54, 416.06, 409.54, \n",
    "                   414.71, 417.46, 415.84, 416.32, 419.14, 418.74, 416.12, 416.72]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2402b4-2abd-4b40-8558-22c0c5684bff",
   "metadata": {},
   "source": [
    "### 25a. sample covariance between nvidia and microsoft stock prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc92725-7a44-46f0-9cb0-339e7a8ae528",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(nvid_p)\n",
    "mean_nvid = sum(nvid_p) / n\n",
    "mean_msft = sum(msft_p) / n\n",
    "mean_appl = sum(appl_p) / n\n",
    "\n",
    "cov_nm = (1/(n - 1)) * sum([(nvid_p[i] - mean_nvid) * (msft_p[i] - mean_msft) for i in range(n)])\n",
    "print(f'Sample Covariance (Nvidia, Microsoft): {cov_nm}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd794f-2303-400a-b104-530bae6c40a5",
   "metadata": {},
   "source": [
    "### 25b. sample variance of apple stock prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99546bda-034e-4b53-97bf-558fd5248386",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_appl = sum([(price - mean_appl) ** 2 for price in appl_p]) / (n - 1)\n",
    "print(f'Sample Variance (Apple): {var_appl}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d9664-1f44-4a16-8de0-0c0a48402688",
   "metadata": {},
   "source": [
    "### 25c. sample covariance of apple stock prices with itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b0723-4268-4596-b438-266485e1a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_appl = (1/(n - 1)) * sum([(appl_p[i] - mean_appl) * (appl_p[i] - mean_appl) for i in range(n)])  \n",
    "print(f'sample Covariance (Apple with itself): {cov_appl}')\n",
    "print('\\n Note that Covariance of a random variable with itself is its Variance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca23047-ac91-479c-99d6-4584ac841bd8",
   "metadata": {},
   "source": [
    "## 25 Alternative\n",
    "Similar to the previous problems, as an alternative, libraries with statistical calculation capabilities such as statistics, numpy, or pandas can be used to calculate the covariance, variance, and correlation coefficient. Below is a solution for this problem using the statistics module from Python's standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee930ff8-693d-43ec-ace4-9bffcdb35b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "cov_nm_stat = statistics.covariance(nvid_p, msft_p)\n",
    "var_appl_stat = statistics.variance(appl_p)\n",
    "cov_appl_stat = statistics.covariance(appl_p, appl_p)\n",
    "\n",
    "print(f'Sample Covariance (Nvidia, Microsoft) using statistics module: {cov_nm_stat}')\n",
    "print(f'Sample Variance (Apple) using statistics module: {var_appl_stat}')\n",
    "print(f'Sample Covariance (Apple with itself): {cov_appl_stat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bcd853-b713-4222-ab1a-84da2f1d187b",
   "metadata": {},
   "source": [
    "## 26. Pearson Correlation Coefficient\n",
    "This snippet calculates the Pearson correlation coefficient using the covariance and variances of the stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80e350-d5da-40ab-aaa9-b31c68688380",
   "metadata": {},
   "source": [
    "### 26a. Pearson correlation coefficient between nvidia and microsoft stock prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954abba-40b3-4be7-910d-0d8888c7db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "stdev_nvid = math.sqrt(1/(n - 1) * sum([(price - mean_nvid) ** 2 for price in nvid_p]))\n",
    "stdev_msft = math.sqrt(1/(n - 1) * sum([(price - mean_msft) ** 2 for price in msft_p]))\n",
    "corr_nm = cov_nm / (stdev_nvid * stdev_msft)\n",
    "print(f'Pearson Correlation Coefficient (Nvidia, Microsoft): {corr_nm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dd442-e0da-4131-bd0e-16dc8d6e7bf3",
   "metadata": {},
   "source": [
    "### 26.b calculate Pearson correlation coefficient of apple stock prices with itself (should be 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b7e45-f662-4668-9dec-c5f6dace833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_appl = cov_appl/var_appl  # Correlation with itself\n",
    "print(f'Pearson Correlation Coefficient (Apple with itself): {corr_appl}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c522aee-b0de-4184-9ae4-1333fb46ae73",
   "metadata": {},
   "source": [
    "## 26. (Alternative)\n",
    "similar to the previous problems, as an alternative, libraries with statistical calculation capabilities such as statistics, numpy, or pandas can be used to calculate the covariance, variance, and correlation coefficient. Below is a solution for this problem using the statistics module from Python's standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50015bf2-7705-46fc-b11d-b754e98a6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "corr_nm_stat = statistics.correlation(nvid_p, msft_p)\n",
    "corr_appl_stat = statistics.correlation(appl_p, appl_p)\n",
    "\n",
    "print(f'Pearson Correlation Coefficient (Nvidia, Microsoft): {corr_nm_stat}')\n",
    "print(f'Pearson Correlation Coefficient (Apple with itself): {corr_appl_stat}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2329a3-b2c2-4cba-8178-f16b675a8285",
   "metadata": {},
   "source": [
    "## 27. Merging Dictionaries of Kids' Favorite Colors\n",
    "This code shows three different ways to merge two dictionaries: using the `update()` method, dictionary unpacking, and using union `|` operator. The resulting merged dictionaries are the same. You can check it with `==` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f37481-a255-4dd7-b256-461588bc0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "kid_color_1 = {'Locas': 'red', 'Ava': 'green', 'Mia': 'orange'}\n",
    "kid_color_2 = {'Evelyn': 'black', 'Mia': 'white'}\n",
    "\n",
    "# Method 1: Using the update() method\n",
    "merged_colors = kid_color_1.copy()  # make a copy to avoid modifying the original\n",
    "merged_colors.update(kid_color_2)  # merge using update method\n",
    "\n",
    "# Method 2: Using dictionary unpacking\n",
    "merged_colors_unpacking = {**kid_color_1, **kid_color_2}  # Merge using unpacking\n",
    "\n",
    "# Method 3: Using union operator\n",
    "merged_colors_union = kid_color_1 | kid_color_2\n",
    "\n",
    "print(f'Merged Colors (update method): {merged_colors}')\n",
    "print(f'Merged Colors (unpacking): {merged_colors_unpacking}')\n",
    "print(f'Merged Colors (union): {merged_colors_union}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9bec6-b145-41f5-8dd7-901598730245",
   "metadata": {},
   "source": [
    "## 28. Merging Sales Data Dictionaries\n",
    "\n",
    "This snippet merges two dictionaries, summing values for keys that exist in both. It uses a `for` loop to check for existing keys and updates the merged dictionary accordingly.eport.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d6e1a-1e7d-496f-9894-97a795d885d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_q_1 = {'tv': 100, 'xbox': 200, 'macbook': 30}\n",
    "sales_q_2 = {'xbox': 150, 'speaker': 5}\n",
    "\n",
    "merged_sales = sales_q_1.copy() # initialize with values from sales_q_1\n",
    "\n",
    "for item, sales in sales_q_2.items():\n",
    "    if item in merged_sales:\n",
    "        merged_sales[item] += sales  # Sum if key exists\n",
    "    else:\n",
    "        merged_sales[item] = sales  # update with a new key\n",
    "\n",
    "print(f'Merged Sales: {merged_sales}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151a84e-53ad-4d18-8a5e-b52acb352c2c",
   "metadata": {},
   "source": [
    "## 29. Filtering Students Based on Grades\n",
    "The code uses list comprehension to filter and create a list of students who have grades above 85.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff9a93-3593-4d73-8aed-badca5268f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = {'Noah': 90, 'Jack': 82, 'Sophia': 97, 'Lily': 92, 'Chloe': 77}\n",
    "\n",
    "above_85_students = [name for name, grade in students.items() if grade > 85]\n",
    "# above line using dictionary's items() method inside a list comprehension\n",
    "\n",
    "print(f'Students with grades above 85: {above_85_students}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f38bc7c-8056-49e5-9a0a-3ac6c464a572",
   "metadata": {},
   "source": [
    "## 30. Mini Case Study: Quarterly Financial Data\n",
    "\n",
    "This snippet creates a list of dictionaries to represent the financial data, accesses specific values, updates entries, and calculates total revenue and expenses, culminating in a summary report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bbc04-c5b7-4394-bbfe-b5ccff9f1e8c",
   "metadata": {},
   "source": [
    "### 30.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef103ca-1de0-4b7c-b9fd-881d470326c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = [\n",
    "    {\n",
    "        'Company': 'Alpha', \n",
    "        'Financials': {\n",
    "            'Q1 Rev': 120_000, \n",
    "            'Q1 Exp': 80_000, \n",
    "            'Q2 Rev': 140_000, \n",
    "            'Q2 Exp': 90_000\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'Company': 'Beta', \n",
    "        'Financials': {\n",
    "            'Q1 Rev': 200_000, \n",
    "            'Q1 Exp': 150_000, \n",
    "            'Q2 Rev': 220_000, \n",
    "            'Q2 Exp': 160_000\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'Company': 'Gamma', \n",
    "        'Financials': {\n",
    "            'Q1 Rev': 300_000, \n",
    "            'Q1 Exp': 250_000, \n",
    "            'Q2 Rev': 320_000, \n",
    "            'Q2 Exp': 240_000\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df3547-00b4-4fb4-bcfd-5739401ee6de",
   "metadata": {},
   "source": [
    "### 30.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd049a-dec2-4aaa-b825-7250f518bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_q2_rev = fin_data[1]['Financials']['Q2 Rev']  # Q2 revenue of Beta\n",
    "print(f'Beta Q2 Revenue: {beta_q2_rev:_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a57d3b-3845-498a-ab20-a8c3e41eb84e",
   "metadata": {},
   "source": [
    "### 30.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b036e09-3aae-4d0b-b2dc-14b89a36b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_exp_total = fin_data[2]['Financials']['Q1 Exp'] + fin_data[2]['Financials']['Q2 Exp']\n",
    "print(f'Total Expenses for Gamma: {gamma_exp_total:_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843ca28-96a5-4bf5-bace-13fe762b1fb3",
   "metadata": {},
   "source": [
    "### 30.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad49d41-8d4c-4a96-bc46-347191e1f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in fin_data:\n",
    "    q1_rev = company['Financials']['Q1 Rev']\n",
    "    q1_exp = company['Financials']['Q1 Exp']\n",
    "    net_prof_q1 = q1_rev - q1_exp   # net profit in Q1\n",
    "    print(f'{company[\"Company\"]} Q1 Net Profit: {net_prof_q1:_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02243f88-8603-4d08-a581-3936289c1724",
   "metadata": {},
   "source": [
    "### 30.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e2099-5c06-42e9-8ddd-b6d679664de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data[0]['Financials']['Q2 Exp'] = 95_000  \n",
    "print(f'Updated Q2 Expenses for Alpha: {fin_data[0][\"Financials\"][\"Q2 Exp\"]:_}')\n",
    "print()\n",
    "\n",
    "for company in fin_data:\n",
    "    q1_rev = company['Financials']['Q1 Rev']\n",
    "    q1_exp = company['Financials']['Q1 Exp']\n",
    "    prof_margin = ((q1_rev - q1_exp) / q1_rev) * 100  # Calculate profit margin\n",
    "    company['Financials']['Q1 Prof Margin'] = prof_margin\n",
    "\n",
    "print(\"UPDATED FINANCIAL DATA:\")\n",
    "for company in fin_data:\n",
    "    print(company)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff43eb-511e-4a20-a114-1911bf10d1d4",
   "metadata": {},
   "source": [
    "### 30.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58811557-e071-4eba-82c0-0268217ce809",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.append({\n",
    "    'Company': 'Delta', \n",
    "    'Financials': {\n",
    "        'Q1 Rev': 180_000, \n",
    "        'Q1 Exp': 130_000, \n",
    "        'Q2 Rev': 190_000, \n",
    "        'Q2 Exp': 140_000\n",
    "    }\n",
    "})\n",
    "print('UPDATED FINANCIAL DATA WITH DELTA:')\n",
    "for company in fin_data:\n",
    "    print(company)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e06cb6-6d0d-46b5-ad4b-dcf6d950bceb",
   "metadata": {},
   "source": [
    "### 30.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287dee7-3d4c-49be-beba-c189ff915deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rev = sum(company['Financials']['Q1 Rev'] + company['Financials']['Q2 Rev'] for company in fin_data)\n",
    "total_exp = sum(company['Financials']['Q1 Exp'] + company['Financials']['Q2 Exp'] for company in fin_data)\n",
    "\n",
    "summary_report = {'Total Revenue': total_rev, 'Total Expenses': total_exp}\n",
    "print('Summary Report:', summary_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
